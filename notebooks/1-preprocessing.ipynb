{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Polaris Prize data...\n",
      "Loaded 200 albums\n",
      "\n",
      "Theme distribution:\n",
      "theme_label\n",
      "Love & Relationships          41\n",
      "Introspection & Philosophy    41\n",
      "Experimental & Abstract       35\n",
      "Social Commentary             32\n",
      "Identity & Heritage           30\n",
      "Place & Landscape             21\n",
      "Name: count, dtype: int64\n",
      "Final dataset: 200 albums\n",
      "Final classes:\n",
      "0: Experimental & Abstract (35 samples)\n",
      "1: Identity & Heritage (30 samples)\n",
      "2: Introspection & Philosophy (41 samples)\n",
      "3: Love & Relationships (41 samples)\n",
      "4: Place & Landscape (21 samples)\n",
      "5: Social Commentary (32 samples)\n",
      "Dataset shape: (200, 11)\n",
      "Missing values:\n",
      "artist              0\n",
      "album               0\n",
      "year                0\n",
      "placement           0\n",
      "genre               0\n",
      "region              0\n",
      "theme_label         0\n",
      "description         0\n",
      "critical_context    0\n",
      "text                0\n",
      "label               0\n",
      "dtype: int64\n",
      "Unique values per column:\n",
      "artist              169\n",
      "album               200\n",
      "year                  5\n",
      "placement             2\n",
      "genre                58\n",
      "region               10\n",
      "theme_label           6\n",
      "description         170\n",
      "critical_context    188\n",
      "text                200\n",
      "label                 6\n",
      "dtype: int64\n",
      "Removed 0 rows due to missing themes and small classes\n",
      "Text quality check: avg length = 162 chars\n",
      "Saved processed_data.csv and label_classes.npy\n"
     ]
    }
   ],
   "source": [
    "# Data Loading & Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"Loading Polaris Prize data...\")\n",
    "df = pd.read_csv('../polaris_training_dataset.csv')\n",
    "original_len = len(df)  \n",
    "print(f\"Loaded {len(df)} albums\")\n",
    "\n",
    "# Show theme distribution\n",
    "print(\"\\nTheme distribution:\")\n",
    "print(df['theme_label'].value_counts())\n",
    "\n",
    "# Create better text features\n",
    "def create_text_features(row):\n",
    "    parts = []\n",
    "    if pd.notna(row['album']):\n",
    "        parts.append(f\"Album: {row['album']}\")\n",
    "    if pd.notna(row['artist']):\n",
    "        parts.append(f\"Artist: {row['artist']}\")\n",
    "    if pd.notna(row['genre']):\n",
    "        parts.append(f\"Genre: {row['genre']}\")\n",
    "    if pd.notna(row['description']) and str(row['description']) != 'nan':\n",
    "        parts.append(f\"Description: {row['description']}\")\n",
    "    if pd.notna(row['critical_context']) and str(row['critical_context']) != 'nan':\n",
    "        parts.append(f\"Context: {row['critical_context']}\")\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "df['text'] = df.apply(create_text_features, axis=1)\n",
    "df = df.dropna(subset=['theme_label'])\n",
    "\n",
    "# Remove classes with too few samples\n",
    "theme_counts = df['theme_label'].value_counts()\n",
    "small_classes = theme_counts[theme_counts < 10].index\n",
    "if len(small_classes) > 0:\n",
    "    print(f\"Removing small classes: {list(small_classes)}\")\n",
    "    df = df[~df['theme_label'].isin(small_classes)]\n",
    "\n",
    "print(f\"Final dataset: {len(df)} albums\")\n",
    "\n",
    "# Encode labels\n",
    "encoder = LabelEncoder()\n",
    "df['label'] = encoder.fit_transform(df['theme_label'])\n",
    "\n",
    "print(\"Final classes:\")\n",
    "for i, theme in enumerate(encoder.classes_):\n",
    "    count = sum(df['label'] == i)\n",
    "    print(f\"{i}: {theme} ({count} samples)\")\n",
    "\n",
    "# EDA\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"Unique values per column:\\n{df.nunique()}\")\n",
    "\n",
    "# Document cleaning decisions\n",
    "print(f\"Removed {original_len - len(df)} rows due to missing themes and small classes\")\n",
    "print(f\"Text quality check: avg length = {df['text'].str.len().mean():.0f} chars\")\n",
    "\n",
    "# Save processed data\n",
    "df.to_csv('processed_data.csv', index=False)\n",
    "np.save('label_classes.npy', encoder.classes_)\n",
    "print(\"Saved processed_data.csv and label_classes.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
